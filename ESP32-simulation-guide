Okay, let's outline how you can simulate the ESP32-CAM server and test your Python OCR client without the physical hardware.

The core idea is to replace the ESP32-CAM's web server component with a simple Python-based web server running on your computer. This simulated server will serve pre-existing image files (containing text) instead of capturing them live. Your Python client will then connect to this *local* server instead of the ESP32's IP address.

**Simulation Approach:**

1.  **Simulated Server (Python):** We'll create a small web server using a framework like Flask (or even Python's built-in `http.server`). This server will listen on a specific port on your local machine (e.g., `localhost:8000`). When it receives a request on a designated path (e.g., `/jpg`), it will read an image file from your disk and send it back as a JPEG response, mimicking the `serveJpg()` function of the ESP32.
2.  **Sample Images:** You'll need a few sample JPEG images containing text that you want to test OCR on. Place these in a folder accessible by the simulated server script.
3.  **Modified Python Client:** You'll use your existing Python client code, but change the URL it connects to from the ESP32's expected IP address to the address of your simulated server (e.g., `http://127.0.0.1:8000/jpg`).




**Part 1: Simulated ESP32-CAM Server (Using Python Flask)**

This script mimics the ESP32 server's role of serving JPEG images.

1.  **Prerequisites:**
    * Install Flask: `pip install Flask`
    * Create a folder named `sample_images` in the same directory where you save the server script.
    * Place some `.jpg` files containing text into the `sample_images` folder (e.g., `image1.jpg`, `image2.jpg`).

2.  **`simulate_esp32_server.py` Code:**

    ```python
    import os
    import random
    from flask import Flask, send_file, Response

    app = Flask(__name__)

    IMAGE_FOLDER = 'sample_images'
    # Get a list of image files from the folder
    try:
        image_files = [f for f in os.listdir(IMAGE_FOLDER) if f.lower().endswith(('.jpg', '.jpeg'))]
        if not image_files:
            print(f"Error: No JPG/JPEG images found in the '{IMAGE_FOLDER}' directory.")
            print("Please create the directory and add some sample images.")
            exit() # Exit if no images are found
        print(f"Found images: {image_files}")
    except FileNotFoundError:
        print(f"Error: Directory '{IMAGE_FOLDER}' not found.")
        print("Please create the directory and add some sample images.")
        exit() # Exit if directory doesn't exist

    @app.route('/')
    def index():
        # Optional: A simple index page to confirm the server is running
        return "Simulated ESP32-CAM Server is running. Access /jpg to get an image."

    @app.route('/jpg')
    def serve_jpg():
        """Mimics the serveJpg() function"""
        if not image_files:
             # Should not happen if initial check passed, but good practice
            return "No images available", 503

        try:
            # --- Simulation Logic ---
            # Select an image to serve (e.g., randomly)
            selected_image_name = random.choice(image_files)
            image_path = os.path.join(IMAGE_FOLDER, selected_image_name)
            print(f"Serving image: {image_path}")

            # Simulate potential capture failure (optional)
            # if random.random() < 0.1: # Simulate a 10% failure rate
            #     print("Simulating CAPTURE FAIL")
            #     return "Simulated capture failure", 503

            # Serve the image file
            return send_file(image_path, mimetype='image/jpeg')

        except FileNotFoundError:
            print(f"Error: Image file not found at {image_path}")
            return "Image file not found", 404
        except Exception as e:
            print(f"An error occurred: {e}")
            return "Internal server error", 500

    if __name__ == '__main__':
        # Run the server, accessible from any IP on the network on port 8000
        # Use '127.0.0.1' if you only want it accessible from your own machine
        print("Starting simulated server on http://0.0.0.0:8000")
        app.run(host='0.0.0.0', port=8000, debug=False) # Set debug=True for more logs if needed
    ```



**Part 2: Adapting the Python OCR Client**

You only need to modify the URL your client tries to fetch the image from.

1.  **Prerequisites:**
    * Ensure you have the necessary libraries installed: `pip install opencv-python numpy pytesseract`
    * Make sure you have the Tesseract OCR engine installed on your system and that `pytesseract` can find it. You might need to configure the path:
        ```python
        # Add this near the top if needed, adjust the path for your OS
        # pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe' # Example for Windows
        # pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract' # Example for Linux
        ```

2.  **`ocr_client.py` (Modified from your example):**

    ```python
    import cv2
    import urllib.request
    import numpy as np
    import pytesseract
    import time # Import time for delays

    # --- CRITICAL CHANGE ---
    # Point this URL to your *simulated* server
    url = 'http://127.0.0.1:8000/jpg' # Use 127.0.0.1 or localhost
    # If server runs on 0.0.0.0 and client is on same machine, 127.0.0.1 is fine.
    # If client is on a different machine, use the server machine's actual IP address.

    # Optional: Configure Tesseract path if needed (see prerequisites)
    # pytesseract.pytesseract.tesseract_cmd = r'<path_to_your_tesseract_executable>'

    print(f"Attempting to connect to simulated server at: {url}")
    print("Ensure the simulate_esp32_server.py script is running.")

    while True:
        try:
            # 1. Fetch JPEG data from simulated server
            img_resp = urllib.request.urlopen(url, timeout=5) # Added timeout

            # 2. Convert it to a NumPy array
            imgnp = np.array(bytearray(img_resp.read()), dtype=np.uint8)

            # 3. Decode it into an OpenCV image
            # cv2.IMREAD_COLOR is default, -1 includes alpha channel if present
            frame = cv2.imdecode(imgnp, cv2.IMREAD_COLOR)

            if frame is None:
                print("Failed to decode image. Skipping frame.")
                time.sleep(1) # Wait a bit before retrying
                continue

            # --- OCR Implementation ---
            # Optional: Pre-processing (Example: convert to grayscale)
            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            # Optional: Apply thresholding etc. if needed for better OCR
            # _, thresh_frame = cv2.threshold(gray_frame, 150, 255, cv2.THRESH_BINARY)

            # 1. Extracts text using Tesseract (using gray frame often works better)
            # --psm 6: Assume a single uniform block of text. Adjust as needed.
            # See Tesseract docs for different PSM modes.
            text = pytesseract.image_to_string(gray_frame, config='--psm 6')
            text = text.strip() # Remove leading/trailing whitespace

            print(f"Detected Text: '{text}'")

            # 2. Overlays the detected text on the original color video stream
            # Use a bounding box or just put text at the top
            cv2.putText(frame, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

            # Display the resulting frame
            cv2.imshow('OCR Stream (Simulated)', frame)

            # --- Wait for key press ---
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'): # Press 'q' to quit
                break
            elif key == ord(' '): # Press 'space' to pause/resume (optional)
                 print("Paused. Press space again to resume.")
                 while True:
                     key2 = cv2.waitKey(0) & 0xFF
                     if key2 == ord(' '):
                         print("Resumed.")
                         break
                     elif key2 == ord('q'):
                        key = key2 # Pass 'q' to outer loop
                        break
                 if key == ord('q'):
                     break


        except urllib.error.URLError as e:
            print(f"Error connecting to server or fetching image: {e}")
            print("Is the simulated server script running?")
            time.sleep(2) # Wait before retrying connection
        except cv2.error as e:
            print(f"OpenCV Error: {e}")
            time.sleep(1)
        except Exception as e:
            print(f"An unexpected error occurred: {e}")
            time.sleep(1) # Wait a bit before retrying

    # Clean up
    cv2.destroyAllWindows()
    print("Client stopped.")

    ```



**How to Run the Simulation:**

1.  **Save the files:** Save the server code as `simulate_esp32_server.py` and the client code as `ocr_client.py` in the same directory.
2.  **Create `sample_images` folder:** In that same directory, create a folder named `sample_images`.
3.  **Add sample images:** Put one or more `.jpg` files containing text into the `sample_images` folder.
4.  **Open two terminals or command prompts:** Navigate both to the directory where you saved the files.
5.  **Start the simulated server:** In the first terminal, run:
    `python simulate_esp32_server.py`
    You should see output indicating the server has started and which images it found.
6.  **Start the OCR client:** In the second terminal, run:
    `python ocr_client.py`
    A window titled "OCR Stream (Simulated)" should appear, displaying images from your `sample_images` folder with the detected text overlaid. The client terminal will print the detected text.

This setup effectively simulates the data flow between your ESP32-CAM and the Python client, allowing you to develop, test, and refine the OCR part of your project without needing the actual hardware. You can easily swap different sample images to test various text types, fonts, and qualities.
